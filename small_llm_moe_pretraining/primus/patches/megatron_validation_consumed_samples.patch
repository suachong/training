diff --git a/megatron/legacy/data/data_samplers.py b/megatron/legacy/data/data_samplers.py
index 1bf1bf5ee..466da3041 100644
--- a/megatron/legacy/data/data_samplers.py
+++ b/megatron/legacy/data/data_samplers.py
@@ -12,7 +12,7 @@ from megatron.core import mpu
 from megatron.core.datasets.utils import Split
 
 
-def build_pretraining_data_loader(dataset, consumed_samples):
+def build_pretraining_data_loader(dataset, consumed_samples, name=""):
     """Build dataloader given an input dataset."""
 
     if dataset is None:
@@ -26,9 +26,12 @@ def build_pretraining_data_loader(dataset, consumed_samples):
     else:
         split = None
 
-    if split == Split.valid and args.full_validation:
+    is_validation = (split == Split.valid) or (name == "validation")
+    if is_validation:
+        eval_samples = args.eval_iters * args.global_batch_size  # 64 * 16 = 1024
+        total_samples = min(len(dataset), eval_samples)  # Cap at 1024 even if dataset is larger
         batch_sampler = MegatronPretrainingSampler(
-            total_samples=len(dataset),
+            total_samples=total_samples,
             consumed_samples=0,
             micro_batch_size=args.micro_batch_size,
             data_parallel_rank=mpu.get_data_parallel_rank(),
diff --git a/megatron/training/training.py b/megatron/training/training.py
index 23a6ba617..9db7795f0 100644
--- a/megatron/training/training.py
+++ b/megatron/training/training.py
@@ -2719,8 +2719,7 @@ def get_train_valid_test_num_samples():
     if args.full_validation:
         eval_samples = None
     else:
-        eval_iters = (args.train_iters // args.eval_interval + 1) * args.eval_iters
-        eval_samples = eval_iters * args.global_batch_size
+        eval_samples = args.eval_iters * args.global_batch_size
     test_iters = args.eval_iters
 
     return (train_samples, eval_samples, test_iters * args.global_batch_size)
@@ -2775,14 +2774,11 @@ def build_train_valid_test_data_loaders(build_train_valid_test_datasets_provider
 
         valid_dataloaders = []
         for valid_d in valid_ds:
-            if args.skip_train or args.full_validation:
-                valid_dataloaders.append(build_pretraining_data_loader(valid_d, 0))
-            else:
-                if args.multiple_validation_sets:
-                    # TODO(bnorick): for multiple validation sets without full validation, args.consumed_valid_samples is not
-                    # correct and needs to be calculated/set per validation set
-                    raise NotImplementedError("--multiple-validation-sets currently requires --full-validation")
-                valid_dataloaders.append(build_pretraining_data_loader(valid_d, args.consumed_valid_samples))
+            if args.multiple_validation_sets and not args.full_validation:
+                # TODO(bnorick): for multiple validation sets without full validation, args.consumed_valid_samples is not
+                # correct and needs to be calculated/set per validation set
+                raise NotImplementedError("--multiple-validation-sets currently requires --full-validation")
+            valid_dataloaders.append(build_pretraining_data_loader(valid_d, 0, "validation"))
         if not args.multiple_validation_sets:
             assert len(valid_dataloaders) == 1
         test_dataloader = build_pretraining_data_loader(test_ds, 0)
